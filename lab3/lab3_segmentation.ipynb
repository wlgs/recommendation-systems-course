{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 3 - segmentacje\n",
    "\n",
    "## Przygotowanie\n",
    "\n",
    " * pobierz i wypakuj dataset: https://data.world/socialmediadata/beeradvocate\n",
    " * [opcjonalnie] Utwórz wirtualne środowisko\n",
    " `python3 -m venv ./recsyslab3`\n",
    " * zainstaluj potrzebne biblioteki:\n",
    " `pip install gensim==3.8.3 scikit-learn==1.3.2 wordcloud==1.8.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 1. - przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importujemy potrzebne pakiety\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import codecs\n",
    "import csv\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'socialmediadata-beeradvocate/data/beer_reviews.csv'\n",
    "SCORE_THRESHOLD = 4 # recenzje z co najmniej taka ocena wezmiemy pod uwage\n",
    "VECTOR_SIZE = 20 # jak dlugie powinny byc wektory osadzen uzytkownikow\n",
    "SEGMENTS_COUNT = 10 # na ile segmentow chcemy podzielic populacje uzytkownikow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytujemy dane\n",
    "\n",
    "def parse_headers(column_names):\n",
    "    beer_id_column =  column_names.index('beer_beerid')\n",
    "    beer_style_column = column_names.index('beer_style')\n",
    "    user_id_column =  column_names.index('review_profilename')\n",
    "    score_column =  column_names.index('review_overall')\n",
    "    return beer_id_column, beer_style_column, user_id_column, score_column\n",
    "\n",
    "\n",
    "def parse_review(line, beer_id_column, beer_style_column, user_id_column, score_column):\n",
    "    return line[beer_id_column], line[beer_style_column], line[user_id_column], float(line[score_column])\n",
    "\n",
    "def read_and_parse_reviews(path, score_threshold):\n",
    "    with codecs.open(PATH, 'r', 'UTF-8') as datafile:\n",
    "        datareader = csv.reader(datafile)\n",
    "        beer_id_column, beer_style_column, user_id_column, score_column = parse_headers(next(datareader))\n",
    "    \n",
    "        users_favourite_beers = defaultdict(list)\n",
    "        for review in datareader:\n",
    "            beer_id, _, user_id, score = parse_review(review, beer_id_column, beer_style_column, user_id_column, score_column)\n",
    "            if score >= score_threshold:\n",
    "                users_favourite_beers[user_id].append(beer_id)\n",
    "\n",
    "    return users_favourite_beers\n",
    "\n",
    "def get_beer_id_to_style_mapping(path):\n",
    "    with codecs.open(PATH, 'r', 'UTF-8') as datafile:\n",
    "        datareader = csv.reader(datafile)\n",
    "        beer_id_column, beer_style_column, user_id_column, score_column = parse_headers(next(datareader))\n",
    "        beer_styles = {}\n",
    "        for review in datareader:\n",
    "            beer_id, beer_style, _, _ = parse_review(review, beer_id_column, beer_style_column, user_id_column, score_column)\n",
    "            beer_styles[beer_id] = beer_style\n",
    "        return beer_styles\n",
    "\n",
    "# otrzymujemy slownik - mapowanie z user_id na liste ulubionych beer_ids\n",
    "users_favourite_beers = read_and_parse_reviews(PATH, SCORE_THRESHOLD)\n",
    "\n",
    "# dodatkowo przygotujmy sobie slownik mapujacy id piwa na nazwe stylu\n",
    "beer_styles = get_beer_id_to_style_mapping(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 2. - osadzenia użytkowników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trenujemy model osadzajacy piwa i uzytkownikow w przestrzeni\n",
    "\n",
    "model = Word2Vec(sentences=users_favourite_beers.values(), size=VECTOR_SIZE, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na podstawie modelu obliczamy wektorowa reprezentacje uzytkownikow\n",
    "\n",
    "def get_mean_vector_for_user(user_favourite_beers, model, vector_size):\n",
    "    # inicjalizujemy wektor zerami\n",
    "    v = np.zeros(vector_size)\n",
    "    \n",
    "    # iterujemy po liscie user_favourite_beers, odczytujemy z modelu wektor reprezentujacy kazde piwo i dodajemy do wektora\n",
    "    #   uzyj: model.wv[beer_id]\n",
    "    # ...\n",
    "    \n",
    "    # normalizujemy wektor - dzielimy kazda wspolrzedna przez liczbe piw\n",
    "    # ...\n",
    "\n",
    "\n",
    "def get_mean_user_vectors(users_favourite_beers, model, vector_size):\n",
    "    # korzystajac z powyzszej funkcji, tworzymy slownik {user_id -> vector}\n",
    "    mean_users_vectors = {}\n",
    "    # ...\n",
    "    return mean_users_vectors\n",
    "\n",
    "user_vectors = get_mean_user_vectors(users_favourite_beers, model, VECTOR_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 3. - klasteryzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klastrujemy uzytkownikow - mozemy uzyc wielu algorytmow, np k-means, agglomerative, BIRCH, ...\n",
    "\n",
    "def get_users_segmentation(user_vectors, vector_size, segments_count, clustering_algorithm):\n",
    "    # rozkladamy slownik user_vectors na liste uzytkownikow i liste wektorow\n",
    "    #  - wazne jest zachowanie tej samej kolejnosci w obu listach\n",
    "    users = # ...\n",
    "    vectors = # ...\n",
    "    \n",
    "    # zamieniamy liste wektorow w macierz\n",
    "    users_array = np.stack(vectors, axis=0)\n",
    "    # zaimplementuj wsparcie dla co najmniej jednego algorytmu wiecej\n",
    "    if clustering_algorithm == 'agglomerative':\n",
    "        clustering = AgglomerativeClustering(n_clusters=segments_count).fit_predict(users_array)\n",
    "        # clustering to lista przypisanych klastrow - i-ty element to klaster, do ktorego nalezy i-ty wektor\n",
    "    \n",
    "    segmentation = {}\n",
    "    # jesli nie pomieszalismy kolejnosci w listach, to mozemy odzyskac mapping user_id -> cluster\n",
    "    # ...\n",
    "    return segmentation\n",
    "\n",
    "segmentation = get_users_segmentation(user_vectors, VECTOR_SIZE, SEGMENTS_COUNT, 'agglomerative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obliczamy licznosci segmentow\n",
    "\n",
    "def get_segment_sizes(segmentation):\n",
    "    # ...\n",
    "\n",
    "get_segment_sizes(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obliczamy metryke jakosci segmentacji\n",
    "# metryka przyjmuje wartosci [-1, 1] - im wiecej, tym lepiej\n",
    "users, user_vectors_list = zip(*user_vectors.items())\n",
    "segments_list = [segmentation[u] for u in users]\n",
    "\n",
    "mean_silhouette = silhouette_score(user_vectors_list, segments_list, metric='euclidean')\n",
    "per_sample_silhouettes = silhouette_samples(user_vectors_list, segments_list, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rysujemy wykres\n",
    "def plot_histogram(values, mean_value):\n",
    "    plt.hist(values, color='c', edgecolor='k', alpha=0.65)\n",
    "    plt.axvline(mean_value, linestyle='dashed', linewidth=1)\n",
    "    _, plot_height = plt.ylim()\n",
    "    plt.text(0, plot_height*1.05, 'Mean: {:.3f}'.format(mean_value))\n",
    "    plt.show()\n",
    "\n",
    "plot_histogram(per_sample_silhouettes, mean_silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 4. - opisy segmentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obliczamy popularnosc styli w segmentach oraz w calej populacji\n",
    "#  - czyli jak czesto kazdy ze styli wystepowal\n",
    "\n",
    "def get_per_segment_styles_popularity(users_favourite_beers, beer_styles, segmentation, segments_count):\n",
    "    beer_styles_per_segment = {i: defaultdict(lambda: 0) for i in range(segments_count)}\n",
    "    # do tego slownika bedziemy sie odwolywac np. tak: beer_styles_per_segment[segment][style]\n",
    "    \n",
    "    for user, beers in users_favourite_beers.items():\n",
    "        # ...\n",
    "    \n",
    "    return beer_styles_per_segment\n",
    "\n",
    "def get_total_styles_popularity(beer_styles_per_segment):\n",
    "    total_popularity = defaultdict(lambda: 0)\n",
    "    # ...\n",
    "    return total_popularity\n",
    "\n",
    "per_segment_styles_popularity = get_per_segment_styles_popularity(users_favourite_beers, beer_styles, segmentation, SEGMENTS_COUNT)\n",
    "total_styles_popularity = get_total_styles_popularity(per_segment_styles_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przygotujmy dwa opisy segmentow - top N najpopularniejszych stylow w kazdym segmencie\n",
    "#   oraz top N unikalnych - to samo, ale popularnosc w segmencie dzielimy przez laczna popularnosc\n",
    "#   dla potrzeb wizualizacji w nastepnym kroku, zwroc slownik {segment_id -> {style_id -> frequency}}\n",
    "\n",
    "def most_popular_styles_per_segment(per_segment_styles_popularity, N):\n",
    "    # ...\n",
    "\n",
    "def most_distinctive_styles_per_segment(total_styles_popularity, per_segment_styles_popularity, N):\n",
    "    # ...\n",
    "     \n",
    "top_N = 50\n",
    "most_popular = most_popular_styles_per_segment(per_segment_styles_popularity, top_N)\n",
    "most_distinctive = most_distinctive_styles_per_segment(total_styles_popularity, per_segment_styles_popularity, top_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 5. - wizualizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teraz mozemy zwizualizowac nasze segmentacje za pomoca word clouds\n",
    "#   zauwaz, jak roznia sie obie metody opisow segmentow oraz opisy miedzy poszczegolnymi segmentami\n",
    "\n",
    "def visualise_styles(most_popular, most_distinctive, segment_id):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    wordcloud1 = WordCloud(random_state=42, background_color='black', colormap='Set2')\n",
    "    wordcloud1.generate_from_frequencies(frequencies=most_popular[segment_id])\n",
    "    ax1.imshow(wordcloud1, interpolation=\"bilinear\")\n",
    "    wordcloud2 = WordCloud(random_state=42, background_color='black', colormap='Set2')\n",
    "    wordcloud2.generate_from_frequencies(frequencies=most_distinctive[segment_id])\n",
    "    ax2.imshow(wordcloud2, interpolation=\"bilinear\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax2.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "visualise_styles(most_popular, most_distinctive, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
